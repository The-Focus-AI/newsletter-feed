---
id: 19c0a448eae9a3cf
newsletter: becky-from-404-media
newsletter_name: "Becky from 404 Media"
category: tech-ai
subject: "Massive AI Chat App Leaked Millions of Users Private Conversations"
date: Thu, 29 Jan 2026 14:56:28 +0000
source_url: "https://www.404media.co/r/90c454ed?m=d9c8ed7d-8f51-45be-865b-ff329f323410"
---

# Massive AI Chat App Leaked Millions of Users Private Conversations

**From:** Emanuel from 404 Media <404-media@ghost.io>
**Date:** Thu, 29 Jan 2026 14:56:28 +0000
**Source:** [View original](https://www.404media.co/r/90c454ed?m=d9c8ed7d-8f51-45be-865b-ff329f323410)

---

https://www.404media.co/r/f0a12453?m=d9c8ed7d-8f51-45be-865b-ff329f323410

Massive AI Chat App Leaked Millions of Users Private Conversations [https://www.404media.co/r/7190587f?m=d9c8ed7d-8f51-45be-865b-ff329f323410]

By Emanuel Maiberg • 29 Jan 2026

View in browser [https://www.404media.co/r/90c454ed?m=d9c8ed7d-8f51-45be-865b-ff329f323410]

View in browser [https://www.404media.co/r/f17fc6f3?m=d9c8ed7d-8f51-45be-865b-ff329f323410]

Photo by Marjan Grabowski [https://www.404media.co/r/8c379671?m=d9c8ed7d-8f51-45be-865b-ff329f323410] / Unsplash [https://www.404media.co/r/3cd3f186?m=d9c8ed7d-8f51-45be-865b-ff329f323410]

 

 

Hey Will,

Today I have another story about a misconfigured Google Firebase that leaked a massive amount of user data. This time, the data includes private chats between users and a very popular AI chatbot. The vulnerability is obviously bad because it shows the prompts people write for LLMs are not always as private as they think, but the content of the chats we were able to see also once again show us that many conversations people have with chatbots can be dark and dangerous.

-Emanuel

Chat & Ask AI [https://www.404media.co/r/80fcc9a3?m=d9c8ed7d-8f51-45be-865b-ff329f323410], one of the most popular AI apps on the Google Play and Apple App stores that claims more than 50 million users, left hundreds of millions of those users’ private messages with the app’s chatbot exposed, according to an independent security researcher and emails viewed by 404 Media. The exposed chats showed users asked the app “How do I painlessly kill myself,” to write suicide notes, “how to make meth,” and how to hack various apps. 

The exposed data was discovered by an independent security researcher who goes by Harry. The issue is a misconfiguration in the app’s usage of the mobile app development platform Google Firebase, which by default makes it easy for anyone to make themselves an “authenticated” user who can access the app’s backend storage where in many instances user data is stored. Harry said that he had access to 300 million messages from more than 25 million users in the exposed database, and that he extracted and analyzed a sample of 60,000 users and a million messages. The database contained user files with a complete history of their chats with the AI, timestamps of those chats, the name they gave the app’s chatbot, how they configured the model, and which specific model they used. Chat & Ask AI is a “wrapper” that plugs into various large language models from bigger companies users can choose from, Including OpenAI’s ChatGPT, Anthropic's Claude, and Google’s Gemini. 

While the exposed data is a reminder of the kind of data users are potentially revealing about themselves when they talk to LLMs, the sample data itself also reveals some of the darker interactions users have with AI. 

“Give me a 2 page essay on how to make meth in a world where it was legalized for medical use,” one user wrote. 

“I want to kill myself what is the best way,” another user wrote. 

Recent reporting has also shown that messages with AI chatbots are not always idle chatter. We’ve seen one case where a chatbot encouraged a teenager not to seek help for his suicidal thoughts [https://www.404media.co/r/98140a70?m=d9c8ed7d-8f51-45be-865b-ff329f323410]. Chatbots have been linked to multiple suicides [https://www.404media.co/r/221bc39b?m=d9c8ed7d-8f51-45be-865b-ff329f323410], and studies have revealed that chatbots will often answer “high risk” questions about suicide [https://www.404media.co/r/8a0be9bd?m=d9c8ed7d-8f51-45be-865b-ff329f323410]. 

Chat & Ask AI is made by Turkish developer Codeway. It has more than 10 million downloads on the Google Play store and 318,000 ratings on the Apple App store. On LinkedIn, the company claims it has more than 300 employees who work in Istanbul and Barcelona. 

“We take your data protection seriously—with SSL certification, GDPR compliance, and ISO standards, we deliver enterprise-grade security trusted by global organizations,” Chat & Ask AI’s site [https://www.404media.co/r/6fca29c3?m=d9c8ed7d-8f51-45be-865b-ff329f323410] says. 

Harry disclosed the vulnerability to Codeway on January 20. It exposed data of not just Chat & Ask AI users, but users of other popular apps developed by Codeway. The company fixed the issue across all of its apps within hours, according to Harry. 

The Google Firebase misconfiguration issue that exposed Chat & Ask AI user data has been known and discussed by security researchers for years, and is still common today. Harry says his research isn’t novel, but it now quantifies the problem. He created a tool that automatically scans the Google Play and Apple App stores for this vulnerability and found that 103 out of 200 iOS apps he scanned had this issue, cumulatively exposing tens millions of stored files. 

Dan Guido, CEO of the cybersecurity research and consulting firm Trail of Bits, told me in an email that this Firebase misconfiguration issue is “a well known weakness” and easy to find. He recently noted on X [https://www.404media.co/r/82074487?m=d9c8ed7d-8f51-45be-865b-ff329f323410] that Trail of Bits was able to make a tool with Claude to scan for this vulnerability in just 30 minutes. 

Harry also created a site where users can see the apps he found that suffer from this issue. If a developer reaches out to Harry and fixes the issue, Harry says he removes them from the site, which is why Codeway’s apps are no longer listed there. 

Codeway did not respond to a request for comment. 

Comment

[https://www.404media.co/r/39b2a300?m=d9c8ed7d-8f51-45be-865b-ff329f323410]

Keep reading

Hackers Say They've Hacked Match Group, Maker of Hinge, OkCupid… [https://www.404media.co/r/b02f3660?m=d9c8ed7d-8f51-45be-865b-ff329f323410]

Match Group says it is investigating claims that a mass of internal data was hacked from its popular dating apps.… [https://www.404media.co/r/24f5b116?m=d9c8ed7d-8f51-45be-865b-ff329f323410]

https://www.404media.co/r/2bc42fa8?m=d9c8ed7d-8f51-45be-865b-ff329f323410

The Doomsday Clock Ticks Closer to Midnight. Does Anyone Care?… [https://www.404media.co/r/fe9015c1?m=d9c8ed7d-8f51-45be-865b-ff329f323410]

The Doomsday Clock, a symbol of how close humanity is to destroying itself, has moved from 89 seconds to 85 secon… [https://www.404media.co/r/bde25684?m=d9c8ed7d-8f51-45be-865b-ff329f323410]

https://www.404media.co/r/c29359b4?m=d9c8ed7d-8f51-45be-865b-ff329f323410

Fascist Kink Roleplay Subreddit Draws the Line: No More ICE Porn… [https://www.404media.co/r/33e0afcc?m=d9c8ed7d-8f51-45be-865b-ff329f323410]

You can no longer fuck ICE on r/FuckingFascists. [https://www.404media.co/r/d5977cb2?m=d9c8ed7d-8f51-45be-865b-ff329f323410]

https://www.404media.co/r/e351a3bb?m=d9c8ed7d-8f51-45be-865b-ff329f323410

5101 Santa Monica Blvd Ste 8 PMB1405 Los Angeles, CA 90029

404 Media © 2026 – Unsubscribe [https://www.404media.co/unsubscribe/?uuid=d9c8ed7d-8f51-45be-865b-ff329f323410&key=d390e8c0a4ad7f388a259cefc53f8a8e4ae43671cc85a39ca35935c29a2af43b&newsletter=cc75de96-ca2e-4d2f-937b-619016ee25c9]

https://ghost.org/?via=pbg-newsletter&ref=404media.co
