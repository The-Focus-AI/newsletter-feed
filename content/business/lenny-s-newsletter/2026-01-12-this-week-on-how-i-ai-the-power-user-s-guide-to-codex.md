---
id: 19bb2fb6941e4086
newsletter: lenny-s-newsletter
newsletter_name: "Lenny's Newsletter"
category: business
subject: "üéôÔ∏èThis week on How I AI: The power user‚Äôs guide to Codex"
date: Mon, 12 Jan 2026 16:03:09 +0000
---

# üéôÔ∏èThis week on How I AI: The power user‚Äôs guide to Codex

**From:** "Lenny's Newsletter" <lenny+how-i-ai@substack.com>
**Date:** Mon, 12 Jan 2026 16:03:09 +0000

---

View this post on the web at https://www.lennysnewsletter.com/p/this-week-on-how-i-ai-the-power-users

Every Monday, host Claire Vo shares a 30- to 45-minute episode with a new guest demoing a practical, impactful way they‚Äôve learned to use AI in their work or life. No pontificating‚Äîjust specific and actionable advice. 
‚ÄúA full software engineering teammate‚Äù: OpenAI product lead on getting the most out of Codex
Brought to you by:
Brex ‚ÄîThe intelligent finance platform built for founders
Graphite ‚ÄîYour AI code review platform
Alexander Embiricos , the product lead for Codex at OpenAI, shares how AI coding agents are actually used in production‚Äîfrom simple fixes to shipping full apps. He breaks down the workflows that make Codex effective at scale, including structured planning with Plans.md, parallel development using Git worktrees, and automated code review across nearly every OpenAI repo. The conversation covers how Codex users dramatically outperformed non-users internally, how OpenAI built the Sora Android app in just 28 days, and what changed with the release of GPT-5.2. We also explore why context matters more than clever prompts, why the real bottleneck is increasingly human judgment rather than code generation, and how AI tools are evolving from standalone destinations into deeply embedded teammates inside existing workflows.
Detailed workflow walkthroughs from this episode:
‚Ä¢ 3 Advanced Codex Workflows for Faster, Smarter Development with OpenAI‚Äôs Alex Embiricos: https://www.chatprd.ai/how-i-ai/advanced-codex-workflows-with-openai-alex-embiricos 
‚Ä¢ How to Use OpenAI Codex to Understand and Modify a New Codebase: https://www.chatprd.ai/how-i-ai/workflows/how-to-use-openai-codex-to-understand-and-modify-a-new-codebase 
‚Ä¢ How to Architect Complex Software Projects with OpenAI‚Äôs Plans.md Technique: https://www.chatprd.ai/how-i-ai/workflows/how-to-architect-complex-software-projects-with-openai-s-plans-md-technique 
‚Ä¢ How to Manage Parallel Development with AI using Git Worktrees and Codex: https://www.chatprd.ai/how-i-ai/workflows/how-to-manage-parallel-development-with-ai-using-git-worktrees-and-codex 
Biggest takeaways:
The productivity gap between power users and everyone else is significant. When roughly half of OpenAI was using Codex, those users were producing about 70% more PRs than non-users. Now virtually all technical staff use it: ‚ÄúWe‚Äôre now at the point where nearly all of technical staff is using Codex constantly.‚Äù
Automated code review has become OpenAI‚Äôs most widely adopted Codex feature. It‚Äôs enabled on nearly every repo at the company and reviews almost all PRs: ‚ÄúThe hit rate on these is really high. We built this feature so that it only points out issues that it‚Äôs very confident in, because human attention is so scarce, we really want to protect it.‚Äù
Structured planning is critical for complex tasks. OpenAI published a blog post about effective planning with AI that includes a meta-plan template (Plans.md) that helps Codex create thorough, milestone-based plans. This approach was key to building the Sora Android app in just 28 days: ‚ÄúWith coding agents, it doesn‚Äôt get easier, but you just move way faster.‚Äù
Git worktrees are a powerful way to parallelize AI coding tasks. Instead of running conflicting changes in the same codebase or creating multiple copies manually, use Git worktrees: ‚ÄúGit has this really nice affordance called a worktree, which basically lets one Git instance track multiple copies of the codebase.‚Äù You can even ask Codex to create and manage these worktrees for you.
The new GPT-5.2 model can solve problems previous models couldn‚Äôt‚Äîoften with significantly less thinking time. Alex cites an example of a bug that no previous model could fix but 5.2 ‚Äúfought for 37 minutes and was like, ‚ÄòThis is the bug.‚Äô And then in fact, that was the bug and he got the bug fixed.‚Äù The model can also deliver strong results with significantly less thinking time than previous versions.
The limiting factor in AI productivity is increasingly about human direction, not code generation. ‚ÄúNow that we can just have ubiquitous code and we can basically prototype things trivially, the hard parts become deciding what actually should make it in, thinking what a product should do, knowing a customer actually.‚Äù
Context is everything when prompting AI. Alex recommends: ‚ÄúI don‚Äôt usually ask for things from the agent without giving context. So I‚Äôll say, ‚ÄòHey, I want you to change this UI from this to this so that users do this‚Äô or ‚Äòbecause we don‚Äôt want people to be confused about XYZ.‚Äô‚Äù He believes product managers often make the best prompters because they‚Äôre used to not being the expert.
Being polite to AI protects your own humanity. While not an official OpenAI stance, Alex believes: ‚ÄúI think it‚Äôs important to be polite to everyone. And I think that if you start not being polite to chat, I think it can wear off on you. And you just start not being polite to other people in your life.‚Äù
The future of AI tools is contextual integration rather than separate destinations. Features like side chat in Atlas and Codex in your IDE represent a shift toward AI understanding your environment: ‚ÄúFor me, the idea of an agent that I don‚Äôt have to map myself to its world is really powerful. So side chat is that. Codex is that too, right? You launch it in a codebase and it‚Äôs in your environment. You don‚Äôt have to go to it.‚Äù
The harness (interface to the model) matters as much as the model itself. As models evolve rapidly, the harness needs to adapt to get the most out of each new capability: ‚ÄúEvery time we ship a model, engineers from the Codex team will test it, think about it, talk to the research team. They‚Äôre working super-closely together to figure out how to make the most out of the model.‚Äù
‚ñ∂Ô∏è Listen now on YouTube  | Spotify  | Apple Podcasts 
If you‚Äôre enjoying these episodes, reply and let me know what you‚Äôd love to learn more about: AI workflows, hiring, growth, product strategy‚Äîanything.
Catch you next week,
Lenny
P.S. Want every new episode delivered the moment it drops? Hit ‚ÄúFollow‚Äù on your favorite podcast app.

Unsubscribe https://substack.com/redirect/2/eyJlIjoiaHR0cHM6Ly93d3cubGVubnlzbmV3c2xldHRlci5jb20vYWN0aW9uL2Rpc2FibGVfZW1haWw_dG9rZW49ZXlKMWMyVnlYMmxrSWpveU5UTTRNVFF5TENKd2IzTjBYMmxrSWpveE9ETTRNemt5TlRJc0ltbGhkQ0k2TVRjMk9ESXpORE0zT0N3aVpYaHdJam94TnprNU56Y3dNemM0TENKcGMzTWlPaUp3ZFdJdE1UQTRORFVpTENKemRXSWlPaUprYVhOaFlteGxYMlZ0WVdsc0luMC5LRVd0ZE5jTHplMUdjOHJNV0ozeUkyZXdFd19fSHRwb3BPX25tWS02clpRIiwicCI6MTgzODM5MjUyLCJzIjoxMDg0NSwiZiI6dHJ1ZSwidSI6MjUzODE0MiwiaWF0IjoxNzY4MjM0Mzc4LCJleHAiOjIwODM4MTAzNzgsImlzcyI6InB1Yi0wIiwic3ViIjoibGluay1yZWRpcmVjdCJ9.gbnVJyPGJKFfEru-WN5Pq06-UD1aV8g9RPv3DgaCteM?
